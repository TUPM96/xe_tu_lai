#!/usr/bin/env python3
"""
Script test Camera Ä‘áº§y Ä‘á»§ trÃªn Raspberry Pi (khÃ´ng cáº§n ROS2)
- Hiá»ƒn thá»‹ áº£nh real-time
- Test lane detection (phÃ¡t hiá»‡n váº¡ch káº» Ä‘Æ°á»ng)
- LÆ°u áº£nh Ä‘á»ƒ kiá»ƒm tra
"""

import cv2
import numpy as np
import sys
import argparse
import time


def detect_lanes(image, roi_top=0.4):
    """
    PhÃ¡t hiá»‡n váº¡ch káº» Ä‘Æ°á»ng (giá»‘ng nhÆ° trong obstacle_avoidance.py)
    
    Args:
        image: áº¢nh input (BGR)
        roi_top: Tá»· lá»‡ pháº§n trÃªn Ä‘á»ƒ bá» qua (0.4 = bá» 40% trÃªn)
    
    Returns:
        image_with_lanes: áº¢nh Ä‘Ã£ váº½ váº¡ch káº» Ä‘Æ°á»ng
        lane_center_offset: Offset tá»« giá»¯a Ä‘Æ°á»ng (-1 Ä‘áº¿n 1)
        lane_detected: True náº¿u phÃ¡t hiá»‡n Ä‘Æ°á»£c váº¡ch
    """
    height, width = image.shape[:2]
    
    # Táº¡o vÃ¹ng quan tÃ¢m (ROI) - pháº§n dÆ°á»›i áº£nh
    roi_top_pixel = int(height * roi_top)
    roi = image[roi_top_pixel:height, :]
    
    # Chuyá»ƒn sang HSV Ä‘á»ƒ dá»… phÃ¡t hiá»‡n mÃ u tráº¯ng
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    
    # Táº¡o mask cho mÃ u tráº¯ng (váº¡ch káº» Ä‘Æ°á»ng)
    lower_white = np.array([0, 0, 200])
    upper_white = np.array([180, 30, 255])
    white_mask = cv2.inRange(hsv, lower_white, upper_white)
    
    # Ãp dá»¥ng Gaussian blur
    blurred = cv2.GaussianBlur(white_mask, (5, 5), 0)
    
    # PhÃ¡t hiá»‡n cáº¡nh báº±ng Canny
    edges = cv2.Canny(blurred, 50, 150)
    
    # PhÃ¡t hiá»‡n Ä‘Æ°á»ng tháº³ng báº±ng HoughLinesP
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=30, 
                           minLineLength=20, maxLineGap=15)
    
    # Táº¡o áº£nh output
    image_with_lanes = image.copy()
    lane_center_offset = 0.0
    lane_detected = False
    
    if lines is not None and len(lines) > 0:
        # PhÃ¢n loáº¡i Ä‘Æ°á»ng tháº³ng thÃ nh bÃªn trÃ¡i vÃ  bÃªn pháº£i
        left_lines = []
        right_lines = []
        center_x = width / 2
        
        for line in lines:
            x1, y1, x2, y2 = line[0]
            if x2 != x1:
                slope = (y2 - y1) / (x2 - x1)
                mid_x = (x1 + x2) / 2
                
                # ÄÆ°á»ng bÃªn trÃ¡i: slope Ã¢m vÃ  náº±m bÃªn trÃ¡i
                if slope < -0.2 and mid_x < center_x:
                    left_lines.append(line[0])
                # ÄÆ°á»ng bÃªn pháº£i: slope dÆ°Æ¡ng vÃ  náº±m bÃªn pháº£i
                elif slope > 0.2 and mid_x > center_x:
                    right_lines.append(line[0])
                
                # Váº½ Ä‘Æ°á»ng tháº³ng phÃ¡t hiá»‡n Ä‘Æ°á»£c
                cv2.line(image_with_lanes, 
                        (x1, y1 + roi_top_pixel), 
                        (x2, y2 + roi_top_pixel), 
                        (0, 255, 0), 2)
        
        # TÃ­nh Ä‘iá»ƒm trung bÃ¬nh
        left_x_points = []
        right_x_points = []
        
        for line in left_lines:
            x1, y1, x2, y2 = line
            if y1 > y2:
                left_x_points.append(x1)
            else:
                left_x_points.append(x2)
        
        for line in right_lines:
            x1, y1, x2, y2 = line
            if y1 > y2:
                right_x_points.append(x1)
            else:
                right_x_points.append(x2)
        
        # TÃ­nh offset tá»« giá»¯a Ä‘Æ°á»ng
        if left_x_points and right_x_points:
            left_x_avg = np.mean(left_x_points)
            right_x_avg = np.mean(right_x_points)
            lane_center = (left_x_avg + right_x_avg) / 2
            lane_center_offset = (lane_center - center_x) / (width / 2)
            lane_detected = True
            
            # Váº½ váº¡ch trÃ¡i/pháº£i
            cv2.line(image_with_lanes, 
                    (int(left_x_avg), height), 
                    (int(left_x_avg), roi_top_pixel), 
                    (255, 0, 0), 3)
            cv2.line(image_with_lanes, 
                    (int(right_x_avg), height), 
                    (int(right_x_avg), roi_top_pixel), 
                    (0, 0, 255), 3)
            cv2.line(image_with_lanes, 
                    (int(lane_center), height), 
                    (int(lane_center), roi_top_pixel), 
                    (0, 255, 255), 2)
        elif left_x_points:
            left_x_avg = np.mean(left_x_points)
            lane_center = left_x_avg + 400  # HD resolution
            lane_center_offset = (lane_center - center_x) / (width / 2)
            lane_detected = True
            cv2.line(image_with_lanes, 
                    (int(left_x_avg), height), 
                    (int(left_x_avg), roi_top_pixel), 
                    (255, 0, 0), 3)
        elif right_x_points:
            right_x_avg = np.mean(right_x_points)
            lane_center = right_x_avg - 400  # HD resolution
            lane_center_offset = (lane_center - center_x) / (width / 2)
            lane_detected = True
            cv2.line(image_with_lanes, 
                    (int(right_x_avg), height), 
                    (int(right_x_avg), roi_top_pixel), 
                    (0, 0, 255), 3)
    
    # Váº½ ROI border
    cv2.line(image_with_lanes, 
            (0, roi_top_pixel), 
            (width, roi_top_pixel), 
            (255, 255, 0), 2)
    
    # Váº½ thÃ´ng tin
    cv2.putText(image_with_lanes, f"Lane detected: {lane_detected}", 
               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(image_with_lanes, f"Offset: {lane_center_offset:.2f}", 
               (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    return image_with_lanes, lane_center_offset, lane_detected


def test_camera_full(device=0, width=1280, height=720, enable_lane_detection=True):
    """
    Test camera Ä‘áº§y Ä‘á»§ vá»›i lane detection
    """
    print(f"ğŸ” Äang má»Ÿ camera device /dev/video{device}...")
    print(f"   KÃ­ch thÆ°á»›c: {width}x{height}")
    print(f"   Lane detection: {'Báº­t' if enable_lane_detection else 'Táº¯t'}")
    print("   Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t")
    print("   Nháº¥n 's' Ä‘á»ƒ lÆ°u áº£nh")
    print("   Nháº¥n 'd' Ä‘á»ƒ báº­t/táº¯t lane detection")
    print("-" * 50)
    
    cap = cv2.VideoCapture(device)
    
    if not cap.isOpened():
        print(f"âŒ KhÃ´ng thá»ƒ má»Ÿ camera /dev/video{device}")
        return False
    
    # DÃ¹ng MJPG codec Ä‘á»ƒ há»— trá»£ HD resolution
    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
    cap.set(cv2.CAP_PROP_FOURCC, fourcc)
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
    
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"âœ… Camera Ä‘Ã£ má»Ÿ!")
    print(f"   KÃ­ch thÆ°á»›c thá»±c táº¿: {actual_width}x{actual_height}")
    print(f"   FPS: {fps}")
    print("-" * 50)
    
    frame_count = 0
    fps_counter = 0
    fps_start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            
            if not ret:
                print("âŒ KhÃ´ng thá»ƒ Ä‘á»c frame")
                break
            
            frame_count += 1
            fps_counter += 1
            
            # TÃ­nh FPS
            current_time = time.time()
            if current_time - fps_start_time >= 1.0:
                actual_fps = fps_counter / (current_time - fps_start_time)
                fps_counter = 0
                fps_start_time = current_time
            else:
                actual_fps = 0
            
            # Lane detection náº¿u Ä‘Æ°á»£c báº­t
            if enable_lane_detection:
                processed_frame, offset, detected = detect_lanes(frame)
            else:
                processed_frame = frame.copy()
                offset = 0.0
                detected = False
            
            # Hiá»ƒn thá»‹ thÃ´ng tin
            info_text = [
                f"Frame: {frame_count}",
                f"FPS: {actual_fps:.1f}",
                f"Lane: {'YES' if detected else 'NO'}",
                f"Offset: {offset:.2f}"
            ]
            
            y_offset = 30
            for i, text in enumerate(info_text):
                cv2.putText(processed_frame, text, (10, y_offset + i * 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.putText(processed_frame, 
                       "Press 'q' to quit, 's' to save, 'd' to toggle detection",
                       (10, processed_frame.shape[0] - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # Hiá»ƒn thá»‹
            cv2.imshow('Camera Test - Lane Detection', processed_frame)
            
            # Xá»­ lÃ½ phÃ­m
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                filename = f"camera_test_{frame_count}.jpg"
                cv2.imwrite(filename, processed_frame)
                print(f"ğŸ’¾ ÄÃ£ lÆ°u: {filename}")
            elif key == ord('d'):
                enable_lane_detection = not enable_lane_detection
                print(f"ğŸ”€ Lane detection: {'Báº­t' if enable_lane_detection else 'Táº¯t'}")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ÄÃ£ dá»«ng")
    except Exception as e:
        print(f"âŒ Lá»—i: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print(f"âœ… ÄÃ£ Ä‘Ã³ng. Tá»•ng frame: {frame_count}")
        return True


def main():
    parser = argparse.ArgumentParser(description='Test Camera Ä‘áº§y Ä‘á»§ vá»›i Lane Detection')
    parser.add_argument('--device', type=int, default=0,
                       help='Device ID camera (máº·c Ä‘á»‹nh: 0)')
    parser.add_argument('--width', type=int, default=1280,
                       help='Chiá»u rá»™ng (máº·c Ä‘á»‹nh: 1280)')
    parser.add_argument('--height', type=int, default=720,
                       help='Chiá»u cao (máº·c Ä‘á»‹nh: 720)')
    parser.add_argument('--no-lane', action='store_true',
                       help='Táº¯t lane detection')
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸ“· TEST CAMERA Äáº¦Y Äá»¦ - Raspberry Pi")
    print("=" * 50)
    
    success = test_camera_full(args.device, args.width, args.height, 
                              enable_lane_detection=not args.no_lane)
    
    if success:
        print("=" * 50)
        print("âœ… Camera test hoÃ n thÃ nh!")
        print("=" * 50)
        sys.exit(0)
    else:
        print("=" * 50)
        print("âŒ Camera test tháº¥t báº¡i")
        print("=" * 50)
        sys.exit(1)


if __name__ == '__main__':
    main()

