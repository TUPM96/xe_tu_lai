#!/usr/bin/env python3
"""
Node x·ª≠ l√Ω xe t·ª± l√°i v·ªõi Ackermann Steering:
- Camera: Ph√°t hi·ªán v·∫°ch k·∫ª ƒë∆∞·ªùng v√† ƒëi·ªÅu ch·ªânh ƒë·ªÉ ƒëi gi·ªØa ƒë∆∞·ªùng (Lane Following)
- LiDAR: Ph√°t hi·ªán v√† tr√°nh v·∫≠t c·∫£n (Obstacle Avoidance)
- Priority: LiDAR (safety) > Camera (navigation)
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan, Image
from geometry_msgs.msg import Twist
import cv2
import numpy as np
import math
from std_msgs.msg import Float32


class AutonomousDrive(Node):
    def __init__(self):
        super().__init__('autonomous_drive')
        
        # Parameters
        # Note: use_sim_time is set by launch file, don't declare it here
        self.declare_parameter('min_distance', 0.5)  # Kho·∫£ng c√°ch t·ªëi thi·ªÉu ƒë·ªÉ d·ª´ng (m)
        self.declare_parameter('safe_distance', 0.8)  # Kho·∫£ng c√°ch an to√†n ƒë·ªÉ tr√°nh (m)
        self.declare_parameter('max_linear_speed', 1.0)  # T·ªëc ƒë·ªô t·ªëi ƒëa (m/s) - PWM 255
        self.declare_parameter('max_angular_speed', 1.0)  # T·ªëc ƒë·ªô quay t·ªëi ƒëa (rad/s)
        self.declare_parameter('front_angle_range', 60)  # G√≥c ph√≠a tr∆∞·ªõc ƒë·ªÉ ki·ªÉm tra (degrees)
        self.declare_parameter('use_camera', True)  # S·ª≠ d·ª•ng camera hay kh√¥ng
        self.declare_parameter('use_lidar', True)   # S·ª≠ d·ª•ng LiDAR ƒë·ªÉ tr√°nh v·∫≠t c·∫£n hay kh√¥ng
        self.declare_parameter('camera_topic', '/camera/image_raw')  # Topic camera
        self.declare_parameter('max_steer_angle', 0.5236)  # G√≥c l√°i t·ªëi ƒëa (rad) ~30 degrees
        self.declare_parameter('debug_camera', False)  # Hi·ªÉn th·ªã debug camera output
        # Tham s·ªë PID ƒëi·ªÅu khi·ªÉn b√°m l√†n
        self.declare_parameter('kp', 0.5)  # Proportional gain
        self.declare_parameter('ki', 0.0)   # Integral gain
        self.declare_parameter('kd', 0.1)  # Derivative gain
        # Tham s·ªë lane detection - C c√†ng cao th√¨ ch·ªâ nh·∫≠n m√†u ƒëen h∆°n (lo·∫°i b·ªè x√°m)
        # Gi·∫£m gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c nhi·ªÅu m√†u ƒëen h∆°n
        self.declare_parameter('lane_threshold_c', 15)  # Gi√° tr·ªã C trong adaptive threshold (gi·∫£m t·ª´ 25 xu·ªëng 15)
        # Tham s·ªë l√†m m∆∞·ª£t (smoothing) ƒë·ªÉ tr√°nh ph·∫£n ·ª©ng qu√° nhanh
        self.declare_parameter('lane_offset_smoothing', 0.7)  # 0.0=kh√¥ng smooth, 0.9=r·∫•t smooth
        self.declare_parameter('lane_dead_zone', 0.05)  # V√πng ch·∫øt - b·ªè qua offset nh·ªè h∆°n gi√° tr·ªã n√†y
        # H·ªá s·ªë gi·∫£m t·ªëc khi v√†o cua (0.0 - 1.0), v√≠ d·ª• 0.5 = gi·∫£m c√≤n 50% t·ªëc ƒë·ªô khi ƒëang ƒë√°nh l√°i
        self.declare_parameter('cornering_speed_factor', 0.6)
        # H·ªá s·ªë t·ªëc ƒë·ªô khi ƒëi th·∫≥ng (0.0 - 1.0), v√≠ d·ª• 0.7 = 70% t·ªëc ƒë·ªô t·ªëi ƒëa khi ƒëi th·∫≥ng
        self.declare_parameter('straight_speed_factor', 1.0)
        # H·ªá s·ªë t·ªëc ƒë·ªô khi r·∫Ω (0.0 - 1.0), v√≠ d·ª• 0.4 = 40% t·ªëc ƒë·ªô t·ªëi ƒëa khi r·∫Ω
        self.declare_parameter('turning_speed_factor', 0.4)
        # Tham s·ªë g√≥c servo (degree) - gi·ªõi h·∫°n v√† g√≥c gi·ªØa
        self.declare_parameter('servo_center_angle', 100.0)  # G√≥c gi·ªØa (ƒëi th·∫≥ng)
        self.declare_parameter('servo_min_angle', 45.0)      # G√≥c t·ªëi thi·ªÉu (r·∫Ω tr√°i t·ªëi ƒëa)
        self.declare_parameter('servo_max_angle', 155.0)     # G√≥c t·ªëi ƒëa (r·∫Ω ph·∫£i t·ªëi ƒëa)
        # Tham s·ªë l√†m m∆∞·ª£t g√≥c servo ƒë·ªÉ tr√°nh chuy·ªÉn g√≥c qu√° g·∫•p
        self.declare_parameter('servo_angle_smoothing', 0.8)  # EMA filter cho g√≥c servo (0.0-1.0)

        self.min_distance = self.get_parameter('min_distance').value
        self.safe_distance = self.get_parameter('safe_distance').value
        self.max_linear_speed = self.get_parameter('max_linear_speed').value
        self.max_angular_speed = self.get_parameter('max_angular_speed').value
        self.front_angle_range = self.get_parameter('front_angle_range').value
        self.use_camera = self.get_parameter('use_camera').value
        self.use_lidar = self.get_parameter('use_lidar').value
        self.max_steer_angle = self.get_parameter('max_steer_angle').value
        self.debug_camera = self.get_parameter('debug_camera').value
        self.kp = float(self.get_parameter('kp').value)
        self.ki = float(self.get_parameter('ki').value)
        self.kd = float(self.get_parameter('kd').value)
        self.lane_threshold_c = int(self.get_parameter('lane_threshold_c').value)
        self.lane_offset_smoothing = float(self.get_parameter('lane_offset_smoothing').value)
        self.lane_dead_zone = float(self.get_parameter('lane_dead_zone').value)
        self.cornering_speed_factor = float(self.get_parameter('cornering_speed_factor').value)
        self.straight_speed_factor = float(self.get_parameter('straight_speed_factor').value)
        self.turning_speed_factor = float(self.get_parameter('turning_speed_factor').value)
        self.servo_center_angle = float(self.get_parameter('servo_center_angle').value)
        self.servo_min_angle = float(self.get_parameter('servo_min_angle').value)
        self.servo_max_angle = float(self.get_parameter('servo_max_angle').value)
        self.servo_angle_smoothing = float(self.get_parameter('servo_angle_smoothing').value)
        
        # PID control variables
        self.pid_integral = 0.0
        self.pid_last_error = 0.0
        self.last_control_time = self.get_clock().now().seconds_nanoseconds()[0] + \
                                 self.get_clock().now().seconds_nanoseconds()[1] / 1e9
        self.smoothed_lane_offset = 0.0  # Offset ƒë√£ ƒë∆∞·ª£c l√†m m∆∞·ª£t
        
        # Servo angle smoothing
        self.last_servo_angle_deg = self.servo_center_angle  # Kh·ªüi t·∫°o ·ªü g√≥c gi·ªØa
        self.smoothed_servo_angle_deg = self.servo_center_angle
        
        # Subscribers
        if self.use_lidar:
            self.scan_sub = self.create_subscription(
                LaserScan,
                '/scan',
                self.scan_callback,
                10
            )
            self.get_logger().info('Da subscribe topic /scan cho LiDAR')
        else:
            self.scan_sub = None
            self.get_logger().info('Bo qua LiDAR (use_lidar=false) - chi su dung camera de bam lan')
        
        if self.use_camera:
            camera_topic = self.get_parameter('camera_topic').value
            self.image_sub = self.create_subscription(
                Image,
                camera_topic,
                self.image_callback,
                10
            )
            self.get_logger().info(f'Da subscribe topic {camera_topic} cho Camera')
            self.latest_image = None
            
            # Publisher cho ·∫£nh camera ƒë√£ v·∫Ω lane detection
            self.image_debug_pub = self.create_publisher(Image, '/camera/image_debug', 10)
        
        # Publisher l·ªánh v·∫≠n t·ªëc t·ªõi Arduino (linear, angular)
        self.cmd_vel_pub = self.create_publisher(
            Twist,
            '/cmd_vel',
            10
        )
        # Publisher l·ªánh g√≥rc servo tr·ª±c ti·∫øp (ƒë∆°n v·ªã ƒë·ªô) t·ªõi Arduino qua arduino_bridge
        self.servo_angle_pub = self.create_publisher(Float32, '/servo_angle_cmd', 10)
        
        # State variables
        self.latest_scan = None
        self.obstacle_detected = False
        self.obstacle_direction = 0.0  # -1: tr√°i, 0: gi·ªØa, 1: ph·∫£i
        self.lane_center_offset = 0.0  # Offset t·ª´ gi·ªØa ƒë∆∞·ªùng (-1 ƒë·∫øn 1)
        self.lane_detected = False
        self.lidar_warning_count = 0  # ƒê·∫øm s·ªë l·∫ßn warning ƒë·ªÉ tr√°nh spam
        self.camera_received_count = 0  # ƒê·∫øm s·ªë frame ƒë√£ nh·∫≠n t·ª´ camera
        self.last_lane_log_time = 0.0  # Th·ªùi gian log cu·ªëi c√πng v·ªÅ lane
        
        # Timer ƒë·ªÉ xu·∫•t l·ªánh ƒëi·ªÅu khi·ªÉn
        self.timer = self.create_timer(0.1, self.control_loop)  # 10 Hz
        
        self.get_logger().info('Autonomous Drive Node da khoi dong!')
        self.get_logger().info(f'Camera: {self.use_camera}, LiDAR: Enabled')
        self.get_logger().info(f'Safe distance: {self.safe_distance}m')
    
    def scan_callback(self, msg):
        """Callback xu ly du lieu LiDAR de phat hien vat can"""
        if self.latest_scan is None:
            self.get_logger().info('Da nhan duoc du lieu LiDAR lan dau!')
        self.latest_scan = msg
        self.process_lidar_data(msg)
    
    def imgmsg_to_cv2(self, img_msg, encoding="bgr8"):
        """
        Convert ROS2 Image message sang OpenCV image (numpy array)
        KH√îNG C·∫¶N cv_bridge!
        """
        if encoding == "bgr8" or encoding == "rgb8":
            # Convert bytes to numpy array
            dtype = np.uint8
            img_buf = np.frombuffer(img_msg.data, dtype=dtype)
            # Reshape to image dimensions
            if img_msg.height * img_msg.width * 3 == len(img_buf):
                img_buf = img_buf.reshape((img_msg.height, img_msg.width, 3))
                # BGR8 is default, RGB8 needs conversion
                if encoding == "rgb8":
                    img_buf = cv2.cvtColor(img_buf, cv2.COLOR_RGB2BGR)
                return img_buf
            else:
                raise ValueError(f"Image size mismatch: expected {img_msg.height * img_msg.width * 3}, got {len(img_buf)}")
        else:
            raise ValueError(f"Encoding {encoding} ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")
    
    def image_callback(self, msg):
        """Callback x·ª≠ l√Ω d·ªØ li·ªáu camera ƒë·ªÉ ph√°t hi·ªán v·∫°ch k·∫ª ƒë∆∞·ªùng"""
        try:
            # Convert ROS Image message sang OpenCV image (KH√îNG C·∫¶N cv_bridge)
            cv_image = self.imgmsg_to_cv2(msg, "bgr8")
            self.latest_image = cv_image
            self.camera_received_count += 1
            
            # Log khi nh·∫≠n ·∫£nh camera l·∫ßn ƒë·∫ßu
            if self.camera_received_count == 1:
                self.get_logger().info('Da nhan duoc anh camera lan dau!')
            
            if self.use_camera:
                self.process_camera_lane_detection(cv_image)
        except Exception as e:
            self.get_logger().error(f'Loi xu ly anh: {str(e)}')
    
    def process_lidar_data(self, scan):
        """X·ª≠ l√Ω d·ªØ li·ªáu LiDAR ƒë·ªÉ ph√°t hi·ªán v·∫≠t c·∫£n"""
        if not self.use_lidar or scan is None:
            return
        
        ranges = np.array(scan.ranges)
        angle_min = scan.angle_min
        angle_increment = scan.angle_increment
        
        # Chuy·ªÉn ƒë·ªïi g√≥c ph√≠a tr∆∞·ªõc sang radians
        front_angle_rad = math.radians(self.front_angle_range / 2)
        
        # T√¨m c√°c ƒëi·ªÉm trong v√πng ph√≠a tr∆∞·ªõc
        num_points = len(ranges)
        front_indices = []
        
        for i in range(num_points):
            angle = angle_min + i * angle_increment
            # Ki·ªÉm tra g√≥c ph√≠a tr∆∞·ªõc (t·ª´ -front_angle/2 ƒë·∫øn +front_angle/2)
            if abs(angle) <= front_angle_rad:
                if not (np.isinf(ranges[i]) or np.isnan(ranges[i])):
                    if ranges[i] < scan.range_max and ranges[i] > scan.range_min:
                        front_indices.append((i, ranges[i], angle))
        
        if not front_indices:
            self.obstacle_detected = False
            return
        
        # T√¨m v·∫≠t c·∫£n g·∫ßn nh·∫•t ph√≠a tr∆∞·ªõc
        min_distance = min([item[1] for item in front_indices])
        closest_obstacle = [item for item in front_indices if item[1] == min_distance][0]
        
        # Ki·ªÉm tra c√≥ v·∫≠t c·∫£n kh√¥ng
        if min_distance < self.safe_distance:
            self.obstacle_detected = True
            # X√°c ƒë·ªãnh h∆∞·ªõng v·∫≠t c·∫£n
            obstacle_angle = closest_obstacle[2]
            if obstacle_angle < 0:
                self.obstacle_direction = -1  # V·∫≠t c·∫£n b√™n tr√°i
            else:
                self.obstacle_direction = 1  # V·∫≠t c·∫£n b√™n ph·∫£i
            
            # Ki·ªÉm tra v·∫≠t c·∫£n ·ªü c·∫£ hai b√™n
            left_obstacles = [item for item in front_indices if item[2] < 0 and item[1] < self.safe_distance]
            right_obstacles = [item for item in front_indices if item[2] > 0 and item[1] < self.safe_distance]
            
            if left_obstacles and right_obstacles:
                # V·∫≠t c·∫£n ·ªü c·∫£ hai b√™n, quay l·∫°i
                self.obstacle_direction = 0
        else:
            self.obstacle_detected = False
    
    def cv2_to_imgmsg(self, cv_image, encoding="bgr8"):
        """Convert OpenCV image sang ROS2 Image message"""
        img_msg = Image()
        img_msg.height, img_msg.width = cv_image.shape[:2]
        
        if encoding == "bgr8":
            img_msg.encoding = "bgr8"
            img_msg.is_bigendian = 0
            img_msg.step = img_msg.width * 3
            img_msg.data = cv_image.tobytes()
        elif encoding == "rgb8":
            img_msg.encoding = "rgb8"
            img_msg.is_bigendian = 0
            img_msg.step = img_msg.width * 3
            img_msg.data = cv_image.tobytes()
        else:
            raise ValueError(f"Encoding {encoding} chua duoc ho tro")
        
        return img_msg
    
    def process_camera_lane_detection(self, image):
        """
        Xu ly camera de phat hien 2 vach DEN 2 ben duong bang CONTOUR DETECTION.
        Cach nay to den toan bo vung vach va tinh duong trung diem chinh xac hon.
        """
        if image is None:
            return

        try:
            height, width = image.shape[:2]
            image_with_lanes = image.copy()
            center_x = width / 2

            # Tao vung quan tam (ROI) - phan duoi anh (vung duong)
            roi_top = int(height * 0.4)  # Bat dau tu 40% chieu cao
            roi = image[roi_top:height, :]
            roi_height = height - roi_top

            # Chuyen sang Grayscale de phat hien vach den
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

            # Ap dung Gaussian blur truoc de giam nhieu
            gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)

            # Dung Adaptive Threshold de tu dong dieu chinh theo anh sang
            # C cao hon = chi nhan mau den hon (loai bo xam)
            # Gi·∫£m C ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c nhi·ªÅu m√†u ƒëen h∆°n (bao g·ªìm c·∫£ x√°m ƒëen)
            black_mask = cv2.adaptiveThreshold(
                gray_blurred,
                255,
                cv2.ADAPTIVE_THRESH_MEAN_C,
                cv2.THRESH_BINARY_INV,
                blockSize=25,
                C=self.lane_threshold_c
            )
            
            # Th·ª≠ th√™m threshold ƒë∆°n gi·∫£n ƒë·ªÉ b·∫Øt m√†u ƒëen n·∫øu adaptive threshold kh√¥ng ƒë·ªß
            # N·∫øu adaptive threshold qu√° kh√≥, d√πng th√™m simple threshold
            _, simple_thresh = cv2.threshold(gray_blurred, 80, 255, cv2.THRESH_BINARY_INV)
            # K·∫øt h·ª£p c·∫£ hai mask (OR operation)
            black_mask = cv2.bitwise_or(black_mask, simple_thresh)

            # Morphological operations de lam sach mask va noi cac vung gan nhau
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
            black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_CLOSE, kernel)
            black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_OPEN, kernel)

            # Tim tat ca contours (vung den)
            contours, _ = cv2.findContours(black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            # Loc contours theo dien tich (loai bo nhieu nho) - gi·∫£m ng∆∞·ª°ng ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c v·∫°ch nh·ªè h∆°n
            min_contour_area = 200  # pixels - gi·∫£m t·ª´ 500 xu·ªëng 200 ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c v·∫°ch nh·ªè h∆°n
            valid_contours = [c for c in contours if cv2.contourArea(c) > min_contour_area]

            # Phan loai contours thanh ben trai va ben phai
            left_contours = []
            right_contours = []

            for contour in valid_contours:
                # Tinh centroid cua contour
                M = cv2.moments(contour)
                if M["m00"] > 0:
                    cx = int(M["m10"] / M["m00"])
                    # Phan loai theo vi tri x cua centroid
                    if cx < center_x * 0.8:  # Vung trai (< 40% width)
                        left_contours.append(contour)
                    elif cx > center_x * 1.2:  # Vung phai (> 60% width)
                        right_contours.append(contour)
                    # Bo qua vung giua (40% - 60%) de tranh nhieu

            # Ve contours len anh debug (xanh duong = trai, do = phai)
            if left_contours:
                cv2.drawContours(image_with_lanes,
                               [c + np.array([[0, roi_top]]) for c in left_contours],
                               -1, (255, 0, 0), cv2.FILLED)
            if right_contours:
                cv2.drawContours(image_with_lanes,
                               [c + np.array([[0, roi_top]]) for c in right_contours],
                               -1, (0, 0, 255), cv2.FILLED)

            # T√≠nh to√°n lane center t·∫°i nhi·ªÅu ƒëi·ªÉm d·ªçc theo v·∫°ch k·∫ª ƒë∆∞·ªùng ƒë·ªÉ ph·∫£n √°nh ƒë·ªô cong
            # Chia ROI th√†nh nhi·ªÅu v√πng ngang ƒë·ªÉ t√≠nh midpoint t·∫°i m·ªói v√πng
            num_horizontal_zones = 5  # Chia th√†nh 5 v√πng t·ª´ d∆∞·ªõi l√™n tr√™n
            lane_centers = []  # L∆∞u c√°c midpoint t·∫°i c√°c v√πng kh√°c nhau
            lane_center = None  # Lane center cu·ªëi c√πng ƒë·ªÉ hi·ªÉn th·ªã
            
            # T√≠nh midpoint t·∫°i m·ªói v√πng ngang
            for zone_idx in range(num_horizontal_zones):
                zone_top = int(roi_height * (zone_idx / num_horizontal_zones))
                zone_bottom = int(roi_height * ((zone_idx + 1) / num_horizontal_zones))
                
                left_x_in_zone = None
                right_x_in_zone = None
                
                # T√¨m ƒëi·ªÉm x c·ªßa v·∫°ch tr√°i trong v√πng n√†y
                if left_contours:
                    all_left_points = np.vstack(left_contours)
                    zone_left_points = all_left_points[
                        (all_left_points[:, :, 1] >= zone_top) & 
                        (all_left_points[:, :, 1] < zone_bottom)
                    ]
                    if len(zone_left_points) > 0:
                        # L·∫•y trung b√¨nh x c·ªßa c√°c ƒëi·ªÉm trong v√πng n√†y
                        left_x_in_zone = np.mean(zone_left_points[:, 0])
                
                # T√¨m ƒëi·ªÉm x c·ªßa v·∫°ch ph·∫£i trong v√πng n√†y
                if right_contours:
                    all_right_points = np.vstack(right_contours)
                    zone_right_points = all_right_points[
                        (all_right_points[:, :, 1] >= zone_top) & 
                        (all_right_points[:, :, 1] < zone_bottom)
                    ]
                    if len(zone_right_points) > 0:
                        right_x_in_zone = np.mean(zone_right_points[:, 0])
                
                # T√≠nh midpoint t·∫°i v√πng n√†y n·∫øu c√≥ c·∫£ 2 v·∫°ch
                if left_x_in_zone is not None and right_x_in_zone is not None:
                    zone_center = (left_x_in_zone + right_x_in_zone) / 2
                    zone_y = (zone_top + zone_bottom) / 2 + roi_top  # Y trong to√†n b·ªô ·∫£nh
                    lane_centers.append((zone_center, zone_y))
                elif left_x_in_zone is not None:
                    # Ch·ªâ c√≥ v·∫°ch tr√°i - ∆∞·ªõc t√≠nh
                    estimated_lane_width = 200  # pixels
                    zone_center = left_x_in_zone + estimated_lane_width
                    zone_y = (zone_top + zone_bottom) / 2 + roi_top
                    lane_centers.append((zone_center, zone_y))
                elif right_x_in_zone is not None:
                    # Ch·ªâ c√≥ v·∫°ch ph·∫£i - ∆∞·ªõc t√≠nh
                    estimated_lane_width = 200  # pixels
                    zone_center = right_x_in_zone - estimated_lane_width
                    zone_y = (zone_top + zone_bottom) / 2 + roi_top
                    lane_centers.append((zone_center, zone_y))
            
            # T√≠nh lane center v√† offset t·ª´ c√°c ƒëi·ªÉm ƒë√£ t√¨m ƒë∆∞·ª£c
            if len(lane_centers) > 0:
                # ∆Øu ti√™n ƒëi·ªÉm ·ªü gi·ªØa ROI (v√πng 2 v√† 3) ƒë·ªÉ t√≠nh offset ch√≠nh x√°c h∆°n
                # Ho·∫∑c c√≥ th·ªÉ d√πng trung b√¨nh c√≥ tr·ªçng s·ªë (ƒëi·ªÉm g·∫ßn camera c√≥ tr·ªçng s·ªë cao h∆°n)
                mid_zones = [i for i in range(len(lane_centers)) if i >= len(lane_centers) // 3 and i <= 2 * len(lane_centers) // 3]
                if mid_zones:
                    # D√πng c√°c ƒëi·ªÉm ·ªü gi·ªØa ƒë·ªÉ t√≠nh offset
                    selected_centers = [lane_centers[i][0] for i in mid_zones]
                    lane_center = np.mean(selected_centers)
                else:
                    # D√πng t·∫•t c·∫£ c√°c ƒëi·ªÉm
                    lane_center = np.mean([lc[0] for lc in lane_centers])
                
                self.lane_center_offset = (lane_center - center_x) / (width / 2)
                self.lane_detected = True
                
                # V·∫Ω ƒë∆∞·ªùng midpoint cong l√™n ·∫£nh ƒë·ªÉ debug
                if len(lane_centers) > 1:
                    points = np.array([[int(lc[0]), int(lc[1])] for lc in lane_centers], np.int32)
                    cv2.polylines(image_with_lanes, [points], False, (0, 255, 255), 3)
            else:
                self.lane_detected = False
                self.lane_center_offset = 0.0

            # Ch·ªâ v·∫Ω ƒë∆∞·ªùng trung ƒëi·ªÉm cong (polylines) - kh√¥ng v·∫Ω ƒë∆∞·ªùng th·∫≥ng
            # ƒê∆∞·ªùng trung ƒëi·ªÉm cong ƒë√£ ƒë∆∞·ª£c v·∫Ω ·ªü tr√™n b·∫±ng polylines m√†u v√†ng

            # Ap dung bo loc lam muot (exponential moving average)
            alpha = self.lane_offset_smoothing
            self.smoothed_lane_offset = alpha * self.smoothed_lane_offset + (1 - alpha) * self.lane_center_offset

            # T√≠nh to√°n g√≥c servo t·ª´ PID (s·∫Ω ƒë∆∞·ª£c t√≠nh trong control_loop, nh∆∞ng c·∫ßn ƒë·ªÉ hi·ªÉn th·ªã)
            # T·∫°m th·ªùi d√πng smoothed_lane_offset ƒë·ªÉ hi·ªÉn th·ªã
            steering_offset = -self.smoothed_lane_offset
            
            # Ve text thong tin
            status_text = "LANE OK" if self.lane_detected else "NO LANE"
            left_text = f"L:{len(left_contours)}" if left_contours else "L:--"
            right_text = f"R:{len(right_contours)}" if right_contours else "R:--"
            offset_text = f"Raw:{self.lane_center_offset:.3f} Smooth:{self.smoothed_lane_offset:.3f}"
            servo_text = f"Servo: {self.smoothed_servo_angle_deg:.1f}¬∞"
            contour_count_text = f"Contours: {len(valid_contours)} (L:{len(left_contours)} R:{len(right_contours)})"
            
            # T√≠nh error ƒë·ªÉ hi·ªÉn th·ªã
            if self.lane_detected:
                raw_error = -self.smoothed_lane_offset
                if abs(raw_error) < self.lane_dead_zone:
                    error_display = raw_error * (abs(raw_error) / self.lane_dead_zone) if self.lane_dead_zone > 0 else raw_error
                else:
                    error_display = raw_error
                error_text = f"Error: {error_display:.3f} (DeadZone: {self.lane_dead_zone:.2f})"
            else:
                error_text = "Error: --"

            cv2.putText(image_with_lanes, f"{status_text} | {left_text} | {right_text}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.putText(image_with_lanes, offset_text, (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.putText(image_with_lanes, error_text, (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            cv2.putText(image_with_lanes, servo_text, (10, 120),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            cv2.putText(image_with_lanes, contour_count_text, (10, 150),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            # V·∫Ω mask ƒë·ªÉ debug (hi·ªÉn th·ªã ·ªü g√≥c tr√™n b√™n ph·∫£i)
            mask_display = cv2.resize(black_mask, (160, 120))
            mask_colored = cv2.cvtColor(mask_display, cv2.COLOR_GRAY2BGR)
            image_with_lanes[10:130, width-170:width-10] = mask_colored
            cv2.putText(image_with_lanes, "MASK", (width-165, 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

            # Ve huong can di
            if self.lane_detected:
                # T√≠nh to√°n g√≥c servo t·ª´ offset ƒë·ªÉ hi·ªÉn th·ªã h∆∞·ªõng
                # T√≠nh g√≥c servo t·ª´ offset (s·∫Ω ƒë∆∞·ª£c t√≠nh ch√≠nh x√°c trong control_loop)
                servo_offset_from_center = self.smoothed_servo_angle_deg - self.servo_center_angle
                normalized_offset = servo_offset_from_center / ((self.servo_max_angle - self.servo_min_angle) / 2)
                
                # Tinh vi tri de ve mui ten chi huong
                arrow_x = int(center_x)
                arrow_y = int(height * 0.75)
                offset_pixels = int(normalized_offset * width * 0.3)
                arrow_end_x = arrow_x + offset_pixels
                arrow_end_y = arrow_y - 60

                # Ve mui ten chi huong (mau vang)
                if abs(offset_pixels) > 5:
                    cv2.arrowedLine(image_with_lanes,
                                   (arrow_x, arrow_y),
                                   (arrow_end_x, arrow_end_y),
                                   (0, 255, 255), 5, tipLength=0.3)

                # Text huong di - d·ª±a tr√™n g√≥c servo th·ª±c t·∫ø
                # servo_offset_from_center < 0: g√≥c nh·ªè h∆°n center -> r·∫Ω tr√°i
                # servo_offset_from_center > 0: g√≥c l·ªõn h∆°n center -> r·∫Ω ph·∫£i
                if abs(servo_offset_from_center) < 2.0:  # G·∫ßn g√≥c gi·ªØa
                    direction_text = "DI THANG"
                    direction_color = (0, 255, 0)
                elif servo_offset_from_center < 0:  # G√≥c < center -> r·∫Ω tr√°i
                    direction_text = f"RE TRAI ({abs(servo_offset_from_center):.1f}¬∞)"
                    direction_color = (255, 165, 0)
                else:  # G√≥c > center -> r·∫Ω ph·∫£i
                    direction_text = f"RE PHAI ({servo_offset_from_center:.1f}¬∞)"
                    direction_color = (255, 165, 0)

                cv2.putText(image_with_lanes, direction_text, (10, 180),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, direction_color, 2)
            else:
                cv2.putText(image_with_lanes, "KHONG THAY LANE", (10, 180),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

            # Publish anh da ve
            if hasattr(self, 'image_debug_pub'):
                ros_image = self.cv2_to_imgmsg(image_with_lanes, "bgr8")
                ros_image.header.stamp = self.get_clock().now().to_msg()
                ros_image.header.frame_id = "camera_link_optical"
                self.image_debug_pub.publish(ros_image)

        except Exception as e:
            self.get_logger().debug(f'Loi xu ly camera: {str(e)}')
            self.lane_detected = False
            self.lane_center_offset = 0.0
    
    def calculate_servo_angle_from_pid(self, error, dt):
        """
        T√≠nh to√°n g√≥c servo t·ª´ lane offset error b·∫±ng PID control
        
        Args:
            error: Lane offset error (-1.0 ƒë·∫øn 1.0, √¢m = l·ªách tr√°i, d∆∞∆°ng = l·ªách ph·∫£i)
            dt: Delta time (seconds)
        
        Returns:
            G√≥c servo (degrees) trong gi·ªõi h·∫°n [servo_min_angle, servo_max_angle]
        """
        # Proportional term
        p_term = self.kp * error
        
        # Integral term (v·ªõi anti-windup)
        self.pid_integral += error * dt
        # Gi·ªõi h·∫°n integral ƒë·ªÉ tr√°nh windup
        max_integral = 1.0 / max(self.ki, 0.001) if self.ki > 0 else 10.0
        self.pid_integral = max(-max_integral, min(max_integral, self.pid_integral))
        i_term = self.ki * self.pid_integral
        
        # Derivative term
        d_error = (error - self.pid_last_error) / max(dt, 0.001)
        d_term = self.kd * d_error
        self.pid_last_error = error
        
        # T·ªïng PID output (normalized t·ª´ -1.0 ƒë·∫øn 1.0)
        pid_output = p_term + i_term + d_term
        
        # TƒÉng ƒë·ªô nh·∫°y ƒë·ªÉ servo quay m·∫°nh h∆°n
        # Nh√¢n v·ªõi h·ªá s·ªë ƒë·ªÉ tƒÉng ph·∫£n ·ª©ng c·ªßa servo
        pid_output = pid_output * 1.5  # TƒÉng 50% ƒë·ªô nh·∫°y
        
        # ƒê·∫£m b·∫£o PID output c√≥ ƒë·ªß ƒë·ªô l·ªõn ƒë·ªÉ ƒëi·ªÅu khi·ªÉn servo
        # N·∫øu error nh·ªè nh∆∞ng kh√¥ng zero, v·∫´n c·∫ßn c√≥ output nh·ªè
        if abs(error) > 0.001 and abs(pid_output) < 0.01:
            # TƒÉng ƒë·ªô nh·∫°y cho error nh·ªè
            pid_output = pid_output * 10.0
        
        pid_output = max(-1.0, min(1.0, pid_output))  # Clamp
        
        # Chuy·ªÉn ƒë·ªïi sang g√≥c servo
        # pid_output = -1.0 -> servo_max_angle (r·∫Ω tr√°i t·ªëi ƒëa)
        # pid_output = 0.0  -> servo_center_angle (ƒëi th·∫≥ng)
        # pid_output = 1.0  -> servo_min_angle (r·∫Ω ph·∫£i t·ªëi ƒëa)
        # ƒê·∫£o d·∫•u ƒë·ªÉ ph√π h·ª£p v·ªõi hardware
        servo_range = (self.servo_max_angle - self.servo_min_angle) / 2.0
        servo_angle = self.servo_center_angle - pid_output * servo_range
        
        # Clamp v√†o gi·ªõi h·∫°n
        servo_angle = max(self.servo_min_angle, min(self.servo_max_angle, servo_angle))
        
        return servo_angle
    
    def control_loop(self):
        """
        V√≤ng l·∫∑p ƒëi·ªÅu khi·ªÉn ch√≠nh cho Ackermann Steering:
        - ∆ØU TI√äN 1 (CAO - SAFETY): LiDAR ƒë·ªÉ tr√°nh v·∫≠t c·∫£n
        - ∆ØU TI√äN 2 (TH·∫§P - NAVIGATION): Camera ƒë·ªÉ ƒëi ƒë√∫ng l√†n ƒë∆∞·ªùng (lane following)
        """
        cmd = Twist()

        # T√≠nh delta th·ªùi gian cho PID (gi·∫£ s·ª≠ timer 0.1s, nh∆∞ng v·∫´n ƒëo ch√≠nh x√°c)
        current_time = self.get_clock().now().seconds_nanoseconds()[0] + \
                       self.get_clock().now().seconds_nanoseconds()[1] / 1e9
        dt = max(0.01, current_time - self.last_control_time)
        self.last_control_time = current_time
        
        # N·∫øu ƒëang d√πng LiDAR, x·ª≠ l√Ω tr∆∞·ªùng h·ª£p ch∆∞a c√≥ d·ªØ li·ªáu LiDAR (ch·∫°y ch·∫≠m ƒë·ªÉ an to√†n)
        if self.use_lidar:
            if self.latest_scan is None:
                if self.lidar_warning_count % 20 == 0:
                    self.get_logger().warn('Chua nhan duoc du lieu LiDAR, chay cham de an toan...')
                self.lidar_warning_count += 1

                # Chay cham khi chua co LiDAR (toc do 50% de an toan)
                cmd.linear.x = self.max_linear_speed * 0.5
                cmd.angular.z = 0.0
                self.cmd_vel_pub.publish(cmd)
                return

            # Reset counter khi da co du lieu
            if self.lidar_warning_count > 0:
                self.lidar_warning_count = 0
                self.get_logger().info('Da nhan duoc du lieu LiDAR, chuyen sang che do tu dong!')
        
        # UU TIEN PHU: Kiem tra vat can bang LiDAR (chi khi co vat can moi can thiep)
        if self.use_lidar and self.obstacle_detected:
            # Co vat can, thuc hien tranh (tam thoi bo qua camera)
            if self.obstacle_direction == 0:
                # Vat can o giua hoac ca hai ben, lui lai va quay
                cmd.linear.x = -self.max_linear_speed * 0.5
                cmd.angular.z = self.max_angular_speed * 0.8
                self.get_logger().info('‚ö†Ô∏è Vat can phia truoc - Lui lai va quay phai')
            elif self.obstacle_direction < 0:
                # Vat can ben trai, quay phai de tranh
                cmd.linear.x = self.max_linear_speed * 0.6
                cmd.angular.z = -self.max_angular_speed * 0.7
                self.get_logger().info('‚ö†Ô∏è Vat can ben trai - Quay phai de tranh')
            else:
                # Vat can ben phai, quay trai de tranh
                cmd.linear.x = self.max_linear_speed * 0.6
                cmd.angular.z = self.max_angular_speed * 0.7
                self.get_logger().info('‚ö†Ô∏è Vat can ben phai - Quay trai de tranh')
        else:
            # KH√îNG c√≥ v·∫≠t c·∫£n (ho·∫∑c ƒë√£ t·∫Øt LiDAR) - S·ª≠ d·ª•ng PID ƒë·ªÉ ƒëi·ªÅu khi·ªÉn g√≥c servo
            if self.use_camera and self.lane_detected:
                # T√≠nh to√°n error t·ª´ lane offset
                # smoothed_lane_offset: √¢m = l·ªách tr√°i, d∆∞∆°ng = l·ªách ph·∫£i
                # error cho PID: d∆∞∆°ng = c·∫ßn r·∫Ω ph·∫£i, √¢m = c·∫ßn r·∫Ω tr√°i
                raw_error = -self.smoothed_lane_offset  # ƒê·∫£o d·∫•u ƒë·ªÉ ph√π h·ª£p v·ªõi PID
                
                # √Åp d·ª•ng dead zone - nh∆∞ng KH√îNG zero error, ch·ªâ gi·∫£m ƒë·ªô nh·∫°y
                # Dead zone ch·ªâ l√†m gi·∫£m error nh·ªè, kh√¥ng lo·∫°i b·ªè ho√†n to√†n
                if abs(raw_error) < self.lane_dead_zone:
                    # Gi·∫£m error nh∆∞ng kh√¥ng zero ƒë·ªÉ PID v·∫´n ho·∫°t ƒë·ªông
                    error = raw_error * (abs(raw_error) / self.lane_dead_zone) if self.lane_dead_zone > 0 else raw_error
                else:
                    error = raw_error
                
                # T√≠nh g√≥c servo t·ª´ PID
                target_servo_angle = self.calculate_servo_angle_from_pid(error, dt)
                
                # L√†m m∆∞·ª£t g√≥c servo ƒë·ªÉ tr√°nh chuy·ªÉn g√≥c qu√° g·∫•p
                alpha = self.servo_angle_smoothing
                self.smoothed_servo_angle_deg = alpha * self.smoothed_servo_angle_deg + (1 - alpha) * target_servo_angle
                
                # G·ª≠i g√≥c servo t·ªõi Arduino
                self.last_servo_angle_deg = self.smoothed_servo_angle_deg
                self.servo_angle_pub.publish(Float32(data=self.last_servo_angle_deg))
                
                # T√≠nh t·ªëc ƒë·ªô d·ª±a tr√™n g√≥c l√°i (gi·∫£m t·ªëc khi v√†o cua, gi·∫£m t·ªëc khi ƒëi th·∫≥ng)
                servo_offset_from_center = abs(self.smoothed_servo_angle_deg - self.servo_center_angle)
                max_servo_offset = (self.servo_max_angle - self.servo_min_angle) / 2.0
                
                # N·∫øu ƒëi th·∫≥ng (g√≥c servo g·∫ßn center)
                if servo_offset_from_center < 3.0:  # Trong v√πng 3 ƒë·ªô t·ª´ center
                    # √Åp d·ª•ng h·ªá s·ªë t·ªëc ƒë·ªô khi ƒëi th·∫≥ng
                    speed_factor = self.straight_speed_factor
                else:
                    # ƒêang r·∫Ω - t√≠nh h·ªá s·ªë gi·∫£m t·ªëc d·ª±a tr√™n g√≥c l√°i
                    # Interpolate gi·ªØa turning_speed_factor (khi r·∫Ω nhi·ªÅu) v√† straight_speed_factor (khi r·∫Ω √≠t)
                    normalized_offset = servo_offset_from_center / max_servo_offset  # 0.0 ƒë·∫øn 1.0
                    # Khi r·∫Ω nhi·ªÅu (normalized_offset = 1.0) -> d√πng turning_speed_factor
                    # Khi r·∫Ω √≠t (normalized_offset g·∫ßn 0) -> d√πng straight_speed_factor
                    speed_factor = self.turning_speed_factor + (self.straight_speed_factor - self.turning_speed_factor) * (1.0 - normalized_offset)
                    speed_factor = max(self.turning_speed_factor, min(self.straight_speed_factor, speed_factor))
                
                cmd.linear.x = self.max_linear_speed * speed_factor
                cmd.angular.z = 0.0  # Kh√¥ng d√πng angular, ch·ªâ d√πng g√≥c servo tr·ª±c ti·∫øp
                
                # Log ƒë·ªãnh k·ª≥ v·ªÅ lane detection (m·ªói 2 gi√¢y)
                if current_time - self.last_lane_log_time >= 2.0:
                    servo_offset = self.smoothed_servo_angle_deg - self.servo_center_angle
                    if abs(servo_offset) < 2.0:
                        direction_str = "DI THANG"
                    elif servo_offset < 0:
                        direction_str = f"RE TRAI ({abs(servo_offset):.1f}¬∞)"
                    else:
                        direction_str = f"RE PHAI ({servo_offset:.1f}¬∞)"
                    
                    self.get_logger().info(
                        f'üì∑ Lane - RawOffset: {self.smoothed_lane_offset:.3f}, RawError: {raw_error:.3f}, '
                        f'Error: {error:.3f}, Servo: {self.smoothed_servo_angle_deg:.1f}¬∞, '
                        f'{direction_str}, Speed: {cmd.linear.x:.2f} m/s'
                    )
                    self.last_lane_log_time = current_time
            else:
                # Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c v·∫°ch k·∫ª ƒë∆∞·ªùng -> D·ª™NG L·∫†I
                cmd.linear.x = 0.0
                cmd.angular.z = 0.0
                # ƒê·∫∑t servo v·ªÅ g√≥c gi·ªØa khi kh√¥ng th·∫•y lane
                self.smoothed_servo_angle_deg = self.servo_center_angle
                self.last_servo_angle_deg = self.servo_center_angle
                self.servo_angle_pub.publish(Float32(data=self.last_servo_angle_deg))
                
                if self.use_camera:
                    # Log ƒë·ªãnh k·ª≥ khi kh√¥ng ph√°t hi·ªán lane (m·ªói 2 gi√¢y)
                    if current_time - self.last_lane_log_time >= 2.0:
                        self.get_logger().warn('üì∑ Khong phat hien lan duong - DUNG LAI')
                        self.last_lane_log_time = current_time
        
        self.cmd_vel_pub.publish(cmd)


def main(args=None):
    rclpy.init(args=args)
    node = None
    
    try:
        node = AutonomousDrive()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        if node:
            node.get_logger().error(f'Loi trong node: {str(e)}')
    finally:
        # D·ª´ng robot tr∆∞·ªõc khi tho√°t (ch·ªâ n·∫øu context c√≤n valid)
        if node:
            try:
                if rclpy.ok():
                    cmd = Twist()
                    node.cmd_vel_pub.publish(cmd)
            except Exception:
                pass  # Ignore errors during shutdown
            
            try:
                node.destroy_node()
            except Exception:
                pass  # Ignore errors during node destruction
        
        # Ch·ªâ shutdown n·∫øu context c√≤n valid
        try:
            if rclpy.ok():
                rclpy.shutdown()
        except Exception:
            pass  # Ignore errors if already shutdown


if __name__ == '__main__':
    main()
